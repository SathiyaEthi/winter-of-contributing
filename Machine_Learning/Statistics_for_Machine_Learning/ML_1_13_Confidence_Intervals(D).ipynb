{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_1_13_Confidence_Intervals(D).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ue6V1A0ukrq"
      },
      "source": [
        "# **Confidence Interval**\n",
        "\n",
        "<p>\n",
        "  Confidence interval is a measure to quantify the uncertainty in an estimated statistic (like mean of a certain quantity) when the true population parameter is unknown.\n",
        "\n",
        "  The reason I specifically mention the term ‘population parameter’ is because, usually when you deal with data, you will have data of a smaller sample from the population. While you can easily compute a sample statistic (example: average weight of sample of 10 adult mice), the true population parameter (example: average weight of ALL adult mice that exists) is usually unknown (not always).\n",
        "\n",
        "In simpler terms, confidence interval provides the upper and lower bounds between which a given estimated statistic can vary. This range between which the statistic can vary is usually referred to as the ‘margin of error’.\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.analyticsindiamag.com/wp-content/uploads/2019/01/ci-arch.gif\" />\n",
        "</p>\n",
        "\n",
        "The CI is often referred to as the margin of error and may be used to graphically depict the uncertainty of an estimate on graphs through the use of error bars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDnZrf0OvGsC"
      },
      "source": [
        "# **Example:**\n",
        "\n",
        "Let’s suppose you want to know the expected annual yield for a given variety of Palm tree in a given region. To know this, you start collecting annual yield data from a small sample of trees. Based on this sample data you want to know the expected yield of that variety ‘in general’ and what could be the range of values the annual yield can take assuming a 95% certainty (confidence)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKkE2aZsxPnw"
      },
      "source": [
        "# **Confidence Interval Formula**\n",
        "\n",
        "The formula and method of estimating confidence interval depends on whether the population’s standard deviation is known on not.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSDCwzt41rBKOvAia_kvT4sRXlY3KGs00QxWQ&usqp=CAU\" />\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyY5rIA8z4EY"
      },
      "source": [
        "# **Types of Confidence Intervals problems**\n",
        "\n",
        "When you speak of confidence intervals, there are largely two types of problems where you would compute confidence intervals. The formula to compute confidence interval changes depending on the type.\n",
        "\n",
        "- **Confidence interval of a sample**.<br/>\n",
        "    - Example: Find the confidence interval for mean weight of adult white mice.\n",
        "\n",
        "\n",
        "-  **Confidence interval of a proportion**<br/>\n",
        "    - Example: Find the confidence interval of the percentage of voters who  voted for candidate A in an election (based only on exit polls data).\n",
        "\n",
        "\n",
        "Depending on the type of problem, you need to apply the appropriate formula to calculate confidence intervals.\n",
        "\n",
        "Secondly, the approach you take to compute the confidence intervals depends on what information you know about the population.\n",
        "\n",
        "For example, in most real world cases, you would only be working with a small sample and not know anything about the population, particularly it’s standard deviation. If that is the case, you will use the T-distribution approach. However, sometimes, you may know the population standard deviation, in which case you will use the Standard normal distribution based approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWBLZDFU16rQ"
      },
      "source": [
        "# **For Classification Accuracy In Machine Learning**\n",
        "\n",
        "A machine learning algorithm is well understood by the data scientists and the engineers who develop them but when the product needs to be pitched, the only parameter that counts is its performance. So, a metric to gauge the performance of a model is necessary.\n",
        "\n",
        "Classification accuracy is used to assess the efficacy of a classification algorithm. To report the classification accuracy of the model alone is not best of practices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJgO__Ke2krz"
      },
      "source": [
        "Classification Accuracy = correct predictions/ total predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2dy0Hb72MvB"
      },
      "source": [
        "It is common to use classification accuracy or classification error (the inverse of accuracy) to describe the skill of a classification predictive model. For example, a model that makes correct predictions of the class outcome variable 75% of the time has a classification accuracy of 75%, calculated as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIkpTSqg2aFE"
      },
      "source": [
        "accuracy = total correct predictions / total predictions made * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMFnbpTO2o3D"
      },
      "source": [
        "Classification accuracy or classification error is a proportion or a ratio. It describes the proportion of correct or incorrect predictions made by the model. Each prediction is a binary decision that could be correct or incorrect. Technically, this is called a Bernoulli trial, named for Jacob Bernoulli. The proportions in a Bernoulli trial have a specific distribution called a binomial distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m89PKMzJ2svr"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://analyticsindiamag.com/wp-content/uploads/2019/01/ci.png\" />\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgD1-rAv27Ms"
      },
      "source": [
        "We can use the assumption of a Gaussian distribution of the proportion (i.e. the classification accuracy or error) to easily calculate the confidence interval.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBFHxmFi2dUA"
      },
      "source": [
        "#In the case of classification error, the radius of the interval can be calculated as:\n",
        "interval = z * sqrt( (error * (1 - error)) / n)\n",
        "#In the case of classification accuracy, the radius of the interval can be calculated as:\n",
        "interval = z * sqrt( (accuracy * (1 - accuracy)) / n)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xndxl23D3a7z"
      },
      "source": [
        "Where interval is the radius of the confidence interval, error and accuracy are classification error and classification accuracy respectively, n is the size of the sample, sqrt is the square root function, and z is a critical value from the Gaussian distribution. Technically, this is called the Binomial proportion confidence interval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7POisf6z3c2l"
      },
      "source": [
        "# **CODE FOR CALCULATING ACCURACY SCORES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObYkOFdW3DF7"
      },
      "source": [
        "# split the data into a train and validation sets\n",
        "X1, X2, y1, y2 = train_test_split(X_train, y_train, test_size=0.5)\n",
        "base_prediction = base_model.predict(X2)\n",
        "error = mean_squared_error(base_prediction, y2) ** 0.5\n",
        "mean = base_model.predict(X_test)\n",
        "st_dev = error\n",
        "X1, X2, y1, y2 = train_test_split(X, y, test_size=0.5)\n",
        "base_model.fit(X1, y1)\n",
        "base_prediction = base_model.predict(X2)\n",
        "validation_error = (base_prediction - y2) ** 2\n",
        "error_model.fit(X2, validation_error)\n",
        "mean = base_model.predict(X_test)\n",
        "st_dev = error_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RHuFjJI3okK"
      },
      "source": [
        "# **COMMON MISCONCEPTIONS**\n",
        "A 95% confidence interval does not mean that for a given realised interval there is a 95% probability that the population parameter lies within the interval. The 95% probability relates to the reliability of the estimation procedure, not to a specific calculated interval.\n",
        "\n",
        "A confidence interval is not a definitive range of plausible values for the sample parameter, though it may be understood as an estimate of plausible values for the population parameter.\n",
        "\n",
        "A particular confidence interval of 95% calculated from an experiment does not mean that there is a 95% probability of a sample parameter from a repeat of the experiment falling within this interval. So, it is essential to remember that:\n",
        "\n",
        "- 95% confidence is confidence that in the long-run 95% of the CIs will include the population mean. It is a confidence in the algorithm and not a statement about a single CI.\n",
        "\n",
        "- In frequentist terms, the CI either contains the population mean or it does not.\n",
        "\n",
        "- There is no relationship between a sample’s variance and it’s mean. Therefore we cannot infer that a single narrow CI is more accurate. In this context “accuracy” refers to the long run coverage of the population mean. Look at the visualisation above and note how much the widths of the CIs vary. They can still be narrow but far away from the true mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW8cFpxM4BPR"
      },
      "source": [
        "# **CONCLUSION**\n",
        "\n",
        "A confidence interval is different from a tolerance interval that describes the bounds of data sampled from the distribution. CI provides bounds on a population parameter, such as a mean, standard deviation, or similar and, to deal with the uncertainty inherent in results derived from data that are themselves only a randomly selected subset of a population.\n",
        "\n",
        "It is said that preferring hypothesis testing to confidence intervals and estimation will lead to fewer statistical misinterpretations. Confidence intervals can be unintuitive and sometimes are as misunderstood as p-values and null hypothesis significance testing. Moreover, CIs are often used to perform hypothesis tests and are therefore prone to the same misuses as p-values.\n",
        "\n",
        "Real world data is filled with noise, is inconsistent, non-linear. So, a single “significant” CI can be mighty useful to draw conclusions which otherwise would be cumbersome.\n",
        "\n"
      ]
    }
  ]
}