{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_1_16_Bootstrap Sampling (D).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa4ChRnblqcL"
      },
      "source": [
        "# **Bootstrap Sampling**\n",
        "\n",
        "In statistics, Bootstrap Sampling is a method that involves drawing of sample data repeatedly with replacement from a data source to estimate a population parameter.\n",
        "\n",
        "Wait – that’s too complex. Let’s break it down and understand the key terms:\n",
        "\n",
        "- Sampling: With respect to statistics, sampling is the process of selecting a subset of items from a vast collection of items (population) to estimate a certain characteristic of the entire population\n",
        "\n",
        "- Sampling with replacement: It means a data point in a drawn sample can reappear in future drawn samples as well\n",
        "\n",
        "- Parameter estimation: It is a method of estimating parameters for the population using samples. A parameter is a measurable characteristic associated with a population. For example, the average height of residents in a city, the count of red blood cells, etc.\n",
        "\n",
        "\n",
        "With that knowledge, go ahead and re-read the above definition again. It’ll make much more sense now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7bNhgyrmBvW"
      },
      "source": [
        "# **Why do We need Bootstrap Sampling ?**\n",
        "\n",
        "This is a fundamental question I’ve seen machine learning enthusiasts grapple with. What is the point of Bootstrap Sampling? Where can you use it? Let me take an example to explain this.\n",
        "\n",
        "Let’s say we want to find the mean height of all the students in a school (which has a total population of 1,000). So, how can we perform this task?\n",
        "\n",
        "One approach is to measure the height of all the students and then compute the mean height. I’ve illustrated this process below:\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/img_1-1.png\" />\n",
        "</p>\n",
        "\n",
        "However, this would be a tedious task. Just think about it, we would have to individually measure the heights of 1,000 students and then compute the mean height. It will take days! We need a smarter approach here.\n",
        "\n",
        "This is where Bootstrap Sampling comes into play.\n",
        "\n",
        "Instead of measuring the heights of all the students, we can draw a random sample of 5 students and measure their heights. We would repeat this process 20 times and then average the collected height data of 100 students (5 x 20). This average height would be an estimate of the mean height of all the students of the school.\n",
        "\n",
        "Pretty straightforward, right? This is the basic idea of Bootstrap Sampling.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zsQiJlsmqzj"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/img_2-1.png\" />\n",
        "</p>\n",
        "\n",
        "<strong> Hence, when we have to estimate a parameter of a large population, we can take the help of Bootstrap Sampling. </strong>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztVWptXRm6RL"
      },
      "source": [
        "# **Bootstrap Sampling in Machine Learning**\n",
        "\n",
        "Bootstrap sampling is used in a machine learning ensemble algorithm called bootstrap aggregating (also called bagging). It helps in avoiding overfitting and improves the stability of machine learning algorithms.\n",
        "\n",
        "In bagging, a certain number of equally sized subsets of a dataset are extracted with replacement. Then, a machine learning algorithm is applied to each of these subsets and the outputs are ensembled as I have illustrated below:\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/Bagging.png\" />\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfT2lw18ncb-"
      },
      "source": [
        "# **Bootstrap Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbKLy2lKlX9r"
      },
      "source": [
        "#importing libraries\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68ufC7bynr9Y",
        "outputId": "3b299a05-1ad7-4503-cc8d-35a409c249d2"
      },
      "source": [
        "# normal distribution \n",
        "x = np.random.normal(loc= 500.0, scale=1.0, size=10000)\n",
        "\n",
        "np.mean(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499.9828980294433"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4jDUDLXnvZK"
      },
      "source": [
        "sample_mean = []\n",
        "\n",
        "# Bootstrap Sampling\n",
        "for i in range(40):\n",
        "  y = random.sample(x.tolist(), 5)\n",
        "  avg = np.mean(y)\n",
        "\n",
        "  sample_mean.append(avg)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG2xy6Dxny2V",
        "outputId": "6a08cd75-928f-47b0-bf14-9a4447ef3464"
      },
      "source": [
        "np.mean(sample_mean)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500.02162469459773"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9bSx4IcoC-_"
      },
      "source": [
        "**As you can see It turns out to be pretty close to the population mean! This is why Bootstrap Sampling is such a useful technique in statistics and machine learning.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLAPm7u_oG3w"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "Here are a few key benefits of bootstrapping:\n",
        "\n",
        "- The estimated parameter by bootstrap sampling is comparable to the actual population parameter\n",
        "\n",
        "- Since we only need a few samples for bootstrapping, the computation requirement is very less\n",
        "\n",
        "- In Random Forest, the bootstrap sample size of even 20% gives a pretty good performance as shown below:\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/rf.png\" />\n",
        "</p>\n",
        "\n",
        "The model performance reaches maximum when the data provided is less than 0.2 fraction of the original dataset."
      ]
    }
  ]
}